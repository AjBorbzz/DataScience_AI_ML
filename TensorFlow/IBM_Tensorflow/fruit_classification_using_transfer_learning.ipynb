{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff3ddecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"keras.src.trainers.data_adapters.py_dataset_adapter\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"keras.src.trainers.epoch_iterator\")\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Suppress all warnings and info messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e351f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the dataset...\n",
      "Download completed.\n",
      "Extracting the dataset in chunks...\n",
      "Extracted 2000 of 12481 files...\n",
      "Extracted 4000 of 12481 files...\n",
      "Extracted 6000 of 12481 files...\n",
      "Extracted 8000 of 12481 files...\n",
      "Extracted 10000 of 12481 files...\n",
      "Extracted 12000 of 12481 files...\n",
      "Extracted 12481 of 12481 files...\n",
      "Dataset successfully extracted to 'fruits-360-original-size'.\n",
      "Cleaned up zip file: fruits-360-original-size.zip\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import zipfile\n",
    "\n",
    "# Define dataset URL and paths\n",
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/4yIRGlIpNfKEGJYMhZV52g/fruits-360-original-size.zip\"\n",
    "\n",
    "local_zip = \"fruits-360-original-size.zip\"\n",
    "extract_dir = \"fruits-360-original-size\"\n",
    "\n",
    "def download_dataset(url, output_file):\n",
    "    \"\"\"Download the dataset using wget in quiet mode.\"\"\"\n",
    "    print(\"Downloading the dataset...\")\n",
    "    subprocess.run([\"wget\", \"-q\", \"-O\", output_file, url], check=True)  # Add `-q` for quiet mode\n",
    "    print(\"Download completed.\")\n",
    "\n",
    "def extract_zip_in_chunks(zip_file, extract_to, batch_size=2000):\n",
    "    \"\"\"\n",
    "    Extract a large zip file in chunks to avoid memory bottlenecks.\n",
    "    Processes a specified number of files (batch_size) at a time.\n",
    "    \"\"\"\n",
    "    print(\"Extracting the dataset in chunks...\")\n",
    "    os.makedirs(extract_to, exist_ok=True)  # Ensure the extraction directory exists\n",
    "    \n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        files = zip_ref.namelist()  # List all files in the archive\n",
    "        total_files = len(files)\n",
    "        \n",
    "        for i in range(0, total_files, batch_size):\n",
    "            batch = files[i:i+batch_size]\n",
    "            for file in batch:\n",
    "                zip_ref.extract(file, extract_to)  # Extract each file in the batch\n",
    "            print(f\"Extracted {min(i+batch_size, total_files)} of {total_files} files...\")\n",
    "    \n",
    "    print(f\"Dataset successfully extracted to '{extract_to}'.\")\n",
    "\n",
    "# Main script execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Download the dataset if not already downloaded\n",
    "    if not os.path.exists(local_zip):\n",
    "        download_dataset(url, local_zip)\n",
    "    else:\n",
    "        print(\"Dataset already downloaded.\")\n",
    "    \n",
    "    # Extract the dataset if not already extracted\n",
    "    if not os.path.exists(extract_dir):\n",
    "        extract_zip_in_chunks(local_zip, extract_dir)\n",
    "    else:\n",
    "        print(\"Dataset already extracted.\")\n",
    "    \n",
    "    # Optional cleanup of the zip file\n",
    "    if os.path.exists(local_zip):\n",
    "        os.remove(local_zip)\n",
    "        print(f\"Cleaned up zip file: {local_zip}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3e076b",
   "metadata": {},
   "source": [
    "### Import necessary libraries and set dataset paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab9f0c4",
   "metadata": {},
   "source": [
    "- `ImageDataGenerator:` For loading images and applying data augmentation.\n",
    "- `VGG16:` Pre-trained model used for transfer learning.\n",
    "- `Sequential:` For building a sequential model.\n",
    "- `Dense, Flatten, Dropout, BatchNormalization:` Layers to customize the model architecture.\n",
    "- `ReduceLROnPlateau, EarlyStopping:` Callbacks for optimizing training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dcabe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# Set dataset paths\n",
    "train_dir = 'fruits-360-original-size/fruits-360-original-size/Training'\n",
    "val_dir = 'fruits-360-original-size/fruits-360-original-size/Validation'\n",
    "test_dir = 'fruits-360-original-size/fruits-360-original-size/Test'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7104befe",
   "metadata": {},
   "source": [
    "### Set up data generators for training, validation, and testing with augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1927200d",
   "metadata": {},
   "source": [
    "- `train_datagen:` Applies rescaling and augmentation (e.g., rotation, zoom) to make the model more robust.\n",
    "- `val_datagen and test_datagen:` Only rescale images for validation/testing.\n",
    "- `flow_from_directory:` Loads images from specified folders into batches for training/validation/testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f89fa6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6231 images belonging to 24 classes.\n",
      "Found 3114 images belonging to 24 classes.\n",
      "Found 3110 images belonging to 24 classes.\n"
     ]
    }
   ],
   "source": [
    "# Image data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Load images from directories\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(64, 64),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(64, 64),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(64, 64),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d124fec",
   "metadata": {},
   "source": [
    "### Define the VGG16-based model architecture with custom layers\n",
    "- `base_model:` Loads VGG16, excluding its dense layers (`include_top=False`).\n",
    "- `for layer in base_model.layers:` Freezes VGG16 layers to retain pre-trained weights.\n",
    "- Custom layers: Flatten the output, then add dense layers with regularization (Dropout) and normalization (BatchNormalization) to enhance learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eacd378",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, BatchNormalization, Dropout\n",
    "\n",
    "# Load VGG16 with pre-trained weights\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Build the model\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(train_generator.num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ff05fa",
   "metadata": {},
   "source": [
    "### Compile the model with appropriate loss and optimizer\n",
    "- `categorical_crossentropy:` Used because this is a multi-class classification task.\n",
    "- `adam:` Adaptive learning rate optimizer that helps in faster convergence.\n",
    "- `metrics=['accuracy']:` Tracks model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c399246",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d30d25f",
   "metadata": {},
   "source": [
    "### Train the model with early stopping and learning rate scheduling\n",
    "- `ReduceLROnPlateau`: Reduces learning rate when validation loss plateaus, allowing better optimization.\n",
    "- `EarlyStopping`: Stops training when validation loss no longer improves, preventing overfitting.\n",
    "- `model.fit`: Trains the model on the `train_generator` and evaluates on `val_generator` each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e858e3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 154ms/step - accuracy: 0.1325 - loss: 3.1987 - val_accuracy: 0.1950 - val_loss: 2.5389 - learning_rate: 0.0010\n",
      "Epoch 2/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 150ms/step - accuracy: 0.4702 - loss: 1.7176 - val_accuracy: 0.4475 - val_loss: 2.0746 - learning_rate: 0.0010\n",
      "Epoch 3/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 149ms/step - accuracy: 0.5927 - loss: 1.3041 - val_accuracy: 0.5900 - val_loss: 1.7265 - learning_rate: 0.0010\n",
      "Epoch 4/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 150ms/step - accuracy: 0.6720 - loss: 1.0746 - val_accuracy: 0.5675 - val_loss: 1.4284 - learning_rate: 0.0010\n",
      "Epoch 5/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 150ms/step - accuracy: 0.7196 - loss: 0.9157 - val_accuracy: 0.6825 - val_loss: 1.1053 - learning_rate: 0.0010\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.mixed_precision import set_global_policy\n",
    "\n",
    "# Define callbacks\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-6, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Enable mixed precision (if on GPU)\n",
    "set_global_policy('float32')\n",
    "\n",
    "steps_per_epoch = 50 \n",
    "validation_steps = 25\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=5,\n",
    "    validation_data=val_generator,  \n",
    "    steps_per_epoch=steps_per_epoch,  \n",
    "    validation_steps=validation_steps,  \n",
    "    callbacks=[lr_scheduler, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5322f474",
   "metadata": {},
   "source": [
    "### Fine-tune the model by unfreezing specific layers in VGG16\n",
    "- `for layer in base_model.layers[-5:]`: Unfreezes the last 5 layers to allow fine-tuning.\n",
    "-  Unfreezing fewer layers is faster and prevents overfitting on small datasets.\n",
    "- `RMSprop(learning_rate=1e-5)`: Optimizer with a lower learning rate to fine-tune carefully without drastic weight changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97ccfb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The base model has 19 layers.\n",
      "Epoch 1/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 193ms/step - accuracy: 0.7582 - loss: 0.8498 - val_accuracy: 0.7775 - val_loss: 0.8511 - learning_rate: 1.0000e-05\n",
      "Epoch 2/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 188ms/step - accuracy: 0.7416 - loss: 0.7324 - val_accuracy: 0.8675 - val_loss: 0.5352 - learning_rate: 1.0000e-05\n",
      "Epoch 3/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 192ms/step - accuracy: 0.7942 - loss: 0.6580 - val_accuracy: 0.8250 - val_loss: 0.5334 - learning_rate: 1.0000e-05\n",
      "Epoch 4/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 192ms/step - accuracy: 0.8289 - loss: 0.5877 - val_accuracy: 0.8525 - val_loss: 0.4561 - learning_rate: 1.0000e-05\n",
      "Epoch 5/5\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 194ms/step - accuracy: 0.8379 - loss: 0.5445 - val_accuracy: 0.9100 - val_loss: 0.3477 - learning_rate: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import tensorflow as tf  # Import TensorFlow for accessing tf.keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Check the number of layers in the base model\n",
    "num_layers = len(base_model.layers)\n",
    "print(f\"The base model has {num_layers} layers.\")\n",
    "\n",
    "# Unfreeze the last 5 layers for fine-tuning\n",
    "for layer in base_model.layers[-5:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Freeze BatchNorm layers to speed up fine-tuning\n",
    "for layer in base_model.layers:\n",
    "    if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "        layer.trainable = False\n",
    "\n",
    "# Re-compile the model with a faster optimizer\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),   # Higher learning rate for faster convergence\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Continue training with fewer steps per epoch\n",
    "history_fine = model.fit(\n",
    "    train_generator,\n",
    "    epochs=5,\n",
    "    validation_data=val_generator,\n",
    "    steps_per_epoch=steps_per_epoch,  # Reduced steps per epoch\n",
    "    validation_steps=validation_steps,  # Reduced validation steps\n",
    "    callbacks=[lr_scheduler, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa62a799",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
