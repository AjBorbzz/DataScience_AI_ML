{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5d6fe75",
   "metadata": {},
   "source": [
    "# Logistic Regression Mean Square Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e66a637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from mpl_toolkits import mplot3d\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae65b1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class plot_error_surfaces(object):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, w_range, b_range, X, Y, n_samples = 30, go = True):\n",
    "        W = np.linspace(-w_range, w_range, n_samples)\n",
    "        B = np.linspace(-b_range, b_range, n_samples)\n",
    "        w, b = np.meshgrid(W, B)    \n",
    "        Z = np.zeros((30, 30))\n",
    "        count1 = 0\n",
    "        self.y = Y.numpy()\n",
    "        self.x = X.numpy()\n",
    "        for w1, b1 in zip(w, b):\n",
    "            count2 = 0\n",
    "            for w2, b2 in zip(w1, b1):\n",
    "                Z[count1, count2] = np.mean((self.y - (1 / (1 + np.exp(-1*w2 * self.x - b2)))) ** 2)\n",
    "                count2 += 1   \n",
    "            count1 += 1\n",
    "        self.Z = Z\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        self.W = []\n",
    "        self.B = []\n",
    "        self.LOSS = []\n",
    "        self.n = 0\n",
    "        if go == True:\n",
    "            plt.figure()\n",
    "            plt.figure(figsize=(7.5, 5))\n",
    "            plt.axes(projection='3d').plot_surface(self.w, self.b, self.Z, rstride=1, cstride=1, cmap='viridis', edgecolor='none')\n",
    "            plt.title('Loss Surface')\n",
    "            plt.xlabel('w')\n",
    "            plt.ylabel('b')\n",
    "            plt.show()\n",
    "            plt.figure()\n",
    "            plt.title('Loss Surface Contour')\n",
    "            plt.xlabel('w')\n",
    "            plt.ylabel('b')\n",
    "            plt.contour(self.w, self.b, self.Z)\n",
    "            plt.show()\n",
    "            \n",
    "     # Setter\n",
    "    def set_para_loss(self, model, loss):\n",
    "        self.n = self.n + 1\n",
    "        self.W.append(list(model.parameters())[0].item())\n",
    "        self.B.append(list(model.parameters())[1].item())\n",
    "        self.LOSS.append(loss)\n",
    "    \n",
    "    # Plot diagram\n",
    "    def final_plot(self): \n",
    "        ax = plt.axes(projection='3d')\n",
    "        ax.plot_wireframe(self.w, self.b, self.Z)\n",
    "        ax.scatter(self.W, self.B, self.LOSS, c='r', marker='x', s=200, alpha=1)\n",
    "        plt.figure()\n",
    "        plt.contour(self.w, self.b, self.Z)\n",
    "        plt.scatter(self.W, self.B, c='r', marker='x')\n",
    "        plt.xlabel('w')\n",
    "        plt.ylabel('b')\n",
    "        plt.show()\n",
    "        \n",
    "    # Plot diagram\n",
    "    def plot_ps(self):\n",
    "        plt.subplot(121)\n",
    "        plt.ylim\n",
    "        plt.plot(self.x, self.y, 'ro', label=\"training points\")\n",
    "        plt.plot(self.x, self.W[-1] * self.x + self.B[-1], label=\"estimated line\")\n",
    "        plt.plot(self.x, 1 / (1 + np.exp(-1 * (self.W[-1] * self.x + self.B[-1]))), label='sigmoid')\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        plt.ylim((-0.1, 2))\n",
    "        plt.title('Data Space Iteration: ' + str(self.n))\n",
    "        plt.show()\n",
    "        plt.subplot(122)\n",
    "        plt.contour(self.w, self.b, self.Z)\n",
    "        plt.scatter(self.W, self.B, c='r', marker='x')\n",
    "        plt.title('Loss Surface Contour Iteration' + str(self.n))\n",
    "        plt.xlabel('w')\n",
    "        plt.ylabel('b')\n",
    "        \n",
    "# Plot the diagram\n",
    "\n",
    "def PlotStuff(X, Y, model, epoch, leg=True):\n",
    "    plt.plot(X.numpy(), model(X).detach().numpy(), label=('epoch ' + str(epoch)))\n",
    "    plt.plot(X.numpy(), Y.numpy(), 'r')\n",
    "    if leg == True:\n",
    "        plt.legend()\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "348a4144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11e6e89d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f211611",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self):\n",
    "        self.x = torch.arange(-1, 1, 0.1).view(-1, 1)\n",
    "        self.y = torch.zeros(self.x.shape[0], 1)\n",
    "        self.y[self.x[:, 0] > 0.2] = 1\n",
    "        self.len = self.x.shape[0]\n",
    "        \n",
    "    # Getter\n",
    "    def __getitem__(self, index):      \n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    # Get Length\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfbb102b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = Data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9910f02",
   "metadata": {},
   "source": [
    "### Create the Model and Total Loss Function (Cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d940698",
   "metadata": {},
   "outputs": [],
   "source": [
    "class logistic_regression(nn.Module):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, n_inputs):\n",
    "        super(logistic_regression, self).__init__()\n",
    "        self.linear = nn.Linear(n_inputs, 1)\n",
    "        \n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        yhat = torch.sigmoid(self.linear(x))\n",
    "        return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fcf21c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = logistic_regression(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e158b638",
   "metadata": {},
   "source": [
    "#### Set the Weight and Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "883a4a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters:  OrderedDict({'linear.weight': tensor([[-5.]]), 'linear.bias': tensor([-10.])})\n"
     ]
    }
   ],
   "source": [
    "model.state_dict() ['linear.weight'].data[0] = torch.tensor([[-5]])\n",
    "model.state_dict() ['linear.bias'].data[0] = torch.tensor([[-10]])\n",
    "print(\"The parameters: \", model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce60a40",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
