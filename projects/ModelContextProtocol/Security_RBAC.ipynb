{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3cd8dbe",
   "metadata": {},
   "source": [
    "### Security & Role-Based Access Control (RBAC) using:\n",
    "\n",
    "* Ollama (for running a local LLM like llama3)\n",
    "\n",
    "* FastAPI (for building a lightweight API backend)\n",
    "\n",
    "* Basic RBAC logic (custom roles + access control)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6921e9f0",
   "metadata": {},
   "source": [
    "Simulate Role-Based Access Control where the user's role (e.g., admin, analyst, or viewer) determines what information or instructions the LLM can access or respond with. This is useful in:\n",
    "\n",
    "* Enterprise security assistants\n",
    "\n",
    "* Internal chatbots with access restrictions\n",
    "\n",
    "* Data governance over LLM usage\n",
    "\n",
    "**Model Context Protocol (MCP)** is a concept to structure and control what context is injected into prompts — especially critical for access-controlled environments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dcff19",
   "metadata": {},
   "source": [
    "### Overview\n",
    "A FastAPI server with `/chat` endpoint\n",
    "\n",
    "Each request includes: `user_input` + `user_role`\n",
    "\n",
    "The backend constructs a role-specific prompt using MCP-style context injection\n",
    "\n",
    "The Ollama model (llama3) runs locally and responds with scoped knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e666c2",
   "metadata": {},
   "source": [
    "#### Requirements\n",
    "```bash\n",
    "pip install fastapi uvicorn ollama\n",
    "ollama pull llama3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768c5f65",
   "metadata": {},
   "source": [
    "#### main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41906809",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "import ollama\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "MODEL_NAME = \"llama3\"\n",
    "\n",
    "# Define allowed roles\n",
    "ROLE_CONTEXTS = {\n",
    "    \"admin\": \"You are speaking to an admin. You can provide system-level insights and internal policies.\",\n",
    "    \"analyst\": \"You are speaking to a security analyst. Answer only with threat detection and incident insights.\",\n",
    "    \"viewer\": \"You are speaking to a general viewer. Avoid exposing sensitive or internal data.\"\n",
    "}\n",
    "\n",
    "# Pydantic model for request\n",
    "class ChatRequest(BaseModel):\n",
    "    user_input: str\n",
    "    user_role: str\n",
    "\n",
    "@app.post(\"/chat\")\n",
    "def chat_endpoint(payload: ChatRequest):\n",
    "    role = payload.user_role.lower()\n",
    "    if role not in ROLE_CONTEXTS:\n",
    "        raise HTTPException(status_code=403, detail=\"Unauthorized role.\")\n",
    "\n",
    "    # Inject context (MCP-style)\n",
    "    system_prompt = ROLE_CONTEXTS[role]\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": payload.user_input}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = ollama.chat(model=MODEL_NAME, messages=messages)\n",
    "        return {\"response\": response['message']['content']}\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30d22f9",
   "metadata": {},
   "source": [
    "### Run the server\n",
    "```bash\n",
    "uvicorn main:app --reload\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dfc1f9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "234f9252",
   "metadata": {},
   "source": [
    "#### Example call with `curl`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78d602f",
   "metadata": {},
   "source": [
    "```bash\n",
    "curl -X POST \"http://127.0.0.1:8000/chat\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -d '{\"user_input\": \"What are the open incidents?\", \"user_role\": \"analyst\"}'\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cb2c07",
   "metadata": {},
   "source": [
    "Why this is MVP-ready\n",
    "\n",
    "✅ Secure Role Check (viewer vs admin)\n",
    "\n",
    "✅ MCP-style prompt context (per role)\n",
    "\n",
    "✅ Modular & extensible (easy to plug into frontend/UI)\n",
    "\n",
    "✅ Works with Ollama locally (offline-friendly)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec18698",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
