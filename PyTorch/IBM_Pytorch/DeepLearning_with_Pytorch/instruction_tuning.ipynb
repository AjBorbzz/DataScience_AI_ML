{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73bc2802",
   "metadata": {},
   "source": [
    "# Instruction-Tuning with LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b9ba3b",
   "metadata": {},
   "source": [
    "Instruction-based fine-tuning, referred to as instruction GPT. It trains the language models to follow specific instructions and generate appropriate responses. For instruction-tuning, the dataset plays an important role as it provides structured examples of instructions, contexts, and responses, allowing the model to learn how to handle various tasks effectively. Instruction GPT often uses human feedback to refine and improve model performance; however, this lab doesn't cover this aspect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09d3b20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user -qq datasets==2.20.0 trl==0.9.6 transformers==4.42.3 peft==0.11.1 tqdm==4.66.4 numpy==1.26.4 pandas==2.2.2 matplotlib==3.9.1 seaborn==0.13.2 scikit-learn==1.5.1 sacrebleu==2.4.2 evaluate==0.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9358c38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in /Users/ajborbz/.local/lib/python3.11/site-packages (0.4.2)\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.5-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /Users/ajborbz/.local/lib/python3.11/site-packages (from evaluate) (2.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/ajborbz/.local/lib/python3.11/site-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /Users/ajborbz/.local/lib/python3.11/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/ajborbz/.local/lib/python3.11/site-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/ajborbz/.local/lib/python3.11/site-packages (from evaluate) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/ajborbz/.local/lib/python3.11/site-packages (from evaluate) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /Users/ajborbz/.local/lib/python3.11/site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /Users/ajborbz/.local/lib/python3.11/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /Users/ajborbz/.local/lib/python3.11/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.5.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /Users/ajborbz/.local/lib/python3.11/site-packages (from evaluate) (0.33.4)\n",
      "Requirement already satisfied: packaging in /Users/ajborbz/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from evaluate) (25.0)\n",
      "Requirement already satisfied: filelock in /Users/ajborbz/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/ajborbz/.local/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (20.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/ajborbz/.local/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (0.7)\n",
      "Requirement already satisfied: aiohttp in /Users/ajborbz/.local/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (3.12.14)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/ajborbz/.local/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/ajborbz/.local/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/ajborbz/.local/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/ajborbz/.local/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/ajborbz/.local/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/ajborbz/.local/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/ajborbz/.local/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/ajborbz/.local/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /Users/ajborbz/.local/lib/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets>=2.0.0->evaluate) (3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in /Users/ajborbz/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from aiosignal>=1.4.0->aiohttp->datasets>=2.0.0->evaluate) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /Users/ajborbz/.local/lib/python3.11/site-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/ajborbz/.local/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ajborbz/.local/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ajborbz/.local/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (2025.7.14)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/ajborbz/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ajborbz/.local/lib/python3.11/site-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/ajborbz/.local/lib/python3.11/site-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ajborbz/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Downloading evaluate-0.4.5-py3-none-any.whl (84 kB)\n",
      "Installing collected packages: evaluate\n",
      "  Attempting uninstall: evaluate\n",
      "    Found existing installation: evaluate 0.4.2\n",
      "    Uninstalling evaluate-0.4.2:\n",
      "      Successfully uninstalled evaluate-0.4.2\n",
      "Successfully installed evaluate-0.4.5\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bcd8b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "import evaluate\n",
    "from trl import SFTConfig, SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from urllib.request import urlopen\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb85fe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d82d69b",
   "metadata": {},
   "source": [
    "### Download the dataset\n",
    "CodeAlpaca 20k dataset, a programming code dataset\n",
    "\n",
    "The CodeAlpaca dataset contains the following elements:\n",
    "\n",
    "\n",
    "- `instruction`: **str**, describes the task the model should perform. Each of the 20K instructions is unique.\n",
    "- `input`: **str**, optional context or input for the task. For example, when the instruction is \"Amend the following SQL query to select distinct elements\", the input is the SQL query. Around 40% of the examples have an input.\n",
    "- `output`: **str**, the answer to the instruction as generated by text-davinci-003.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07e08680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-07-14 14:15:51--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/WzOT_CwDALWedTtXjwH7bA/CodeAlpaca-20k.json\n",
      "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.45.118.108\n",
      "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.45.118.108|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6957007 (6.6M) [application/json]\n",
      "Saving to: ‘CodeAlpaca-20k.json’\n",
      "\n",
      "CodeAlpaca-20k.json 100%[===================>]   6.63M  3.20MB/s    in 2.1s    \n",
      "\n",
      "2025-07-14 14:15:58 (3.20 MB/s) - ‘CodeAlpaca-20k.json’ saved [6957007/6957007]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/WzOT_CwDALWedTtXjwH7bA/CodeAlpaca-20k.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51b5b714",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 20022 examples [00:00, 1439587.81 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['output', 'instruction', 'input'],\n",
       "    num_rows: 20022\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"json\", data_files=\"CodeAlpaca-20k.json\", split=\"train\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf36fcee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': 'arr = [2, 4, 6, 8, 10]',\n",
       " 'instruction': 'Create an array of length 5 which contains all even numbers between 1 and 10.',\n",
       " 'input': ''}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fb1bdf",
   "metadata": {},
   "source": [
    "### Focus on the `input`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "527e2306",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 20022/20022 [00:00<00:00, 231072.24 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.filter(lambda example: example[\"input\"] == '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23fd75e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': 'arr = [2, 4, 6, 8, 10]',\n",
       " 'instruction': 'Create an array of length 5 which contains all even numbers between 1 and 10.',\n",
       " 'input': ''}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79b20545",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff8d186e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['output', 'instruction', 'input'],\n",
       "    num_rows: 9764\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77a273f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['output', 'instruction', 'input'],\n",
       "        num_rows: 7811\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['output', 'instruction', 'input'],\n",
       "        num_rows: 1953\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_split = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = dataset_split['train']\n",
    "test_dataset = dataset_split['test']\n",
    "dataset_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d96e813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a small set of data for the resource limitation\n",
    "# This dataset will be only used for evaluation parts, not for the training\n",
    "tiny_test_dataset=test_dataset.select(range(10))\n",
    "tiny_train_dataset=train_dataset.select(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f6607a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['output', 'instruction', 'input'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiny_test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fd3f36",
   "metadata": {},
   "source": [
    "# Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d571cead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base model\n",
    "model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff536716",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\", padding_side='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e28e026",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a7f936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_prompts_func(mydataset):\n",
    "    output_texts = []\n",
    "    for i in range(len(mydataset['instruction'])):\n",
    "        text = (\n",
    "            f\"### Instruction:\\n{mydataset['instruction'][i]}\"\n",
    "            f\"\\n\\n### Response:\\n{mydataset['output'][i]}</s>\"\n",
    "        )\n",
    "        output_texts.append(text)\n",
    "    return output_texts\n",
    "\n",
    "def formatting_prompts_func_no_response(mydataset):\n",
    "    output_texts = []\n",
    "    for i in range(len(mydataset['instruction'])):\n",
    "        text = (\n",
    "            f\"### Instruction:\\n{mydataset['instruction'][i]}\"\n",
    "            f\"\\n\\n### Response:\\n\"\n",
    "        )\n",
    "        output_texts.append(text)\n",
    "    return output_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c136b0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_outputs = []\n",
    "instructions_with_responses = formatting_prompts_func(test_dataset)\n",
    "instructions = formatting_prompts_func_no_response(test_dataset)\n",
    "for i in tqdm(range(len(instructions_with_responses))):\n",
    "    tokenized_instruction_with_response = tokenizer(instructions_with_responses[i], return_tensors=\"pt\", max_length=1024, truncation=True, padding=False)\n",
    "    tokenized_instruction = tokenizer(instructions[i], return_tensors=\"pt\")\n",
    "    expected_output = tokenizer.decode(tokenized_instruction_with_response['input_ids'][0][len(tokenized_instruction['input_ids'][0])-1:], skip_special_tokens=True)\n",
    "    expected_outputs.append(expected_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb15fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('############## instructions ##############\\n' + instructions[0])\n",
    "print('############## instructions_with_responses ##############\\n' + instructions_with_responses[0])\n",
    "print('\\n############## expected_outputs ##############' + expected_outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe9763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListDataset(Dataset):\n",
    "    def __init__(self, original_list):\n",
    "        self.original_list = original_list\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.original_list)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.original_list[i]\n",
    "\n",
    "instructions_torch = ListDataset(instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3f3a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions_torch[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86baa1a5",
   "metadata": {},
   "source": [
    "### Test the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c68271",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_pipeline = pipeline(\"text-generation\",\n",
    "                        model=model,\n",
    "                        tokenizer=tokenizer,\n",
    "                        device=device,\n",
    "                        batch_size=2,\n",
    "                        max_length=50,\n",
    "                        truncation=True,\n",
    "                        padding=False,\n",
    "                        return_full_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421d817f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
