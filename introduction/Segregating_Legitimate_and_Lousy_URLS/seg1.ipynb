{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "A URL can include either **Hypertext Transfer Protocol (HTTP)** or the **Hypertext Transfer Protocol Secure (HTTPS)**. Other types of protocols include the **File Transfer Protocol (FTP)**, **Siimple Mail Transfer (SMTP)**, and others, such as telnet, DNS, and so on.\n",
    "\n",
    "A URL consists of the top-level domain, hostname, paths, and port of the web address.\n",
    "\n",
    "A Lousy URLs are URLs that have been created with malicious intent. They are often the precursors to cyberattacjs that may happen in the near future. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random \n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "import urllib\n",
    "from xml.dom import minidom \n",
    "import csv \n",
    "import pygeoip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_cleanse(web_url):\n",
    "    web_url = web_url.lower()  # Convert to lowercase\n",
    "    parsed_url = urlparse(web_url)\n",
    "    \n",
    "    # Extract domain and path separately\n",
    "    domain_parts = re.split(r'[.\\-]', parsed_url.netloc)  # Split by dot & hyphen\n",
    "    path_parts = re.split(r'[\\/\\-]', parsed_url.path)  # Split by slash & hyphen\n",
    "    \n",
    "    # Remove common TLDs and empty strings\n",
    "    common_tlds = {'com', 'net', 'org', 'gov', 'edu', 'co', 'uk', 'us'}\n",
    "    url_tokens = [part for part in (domain_parts + path_parts) if part and part not in common_tlds]\n",
    "\n",
    "    return list(set(url_tokens))  # Return unique tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = url_cleanse(\"https://www.Iamstrongerthanthe_mountain.com/Dataset/ForgiveMe\")\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lousy URLs** are URLs that have been created with malicious intent. They are often the precursors to cyberattacks that may happen in the near future. These kinds of urls can hit pretty close to home, leaving each one of us very vulnerable to bad sites that we might visit on purpose or by accident.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drive-by download URLS** are URLS that promote the unintended download of software from websites. They could be downloaded when a naive user first clicks on a URL, without knowing the consequences of this action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Command and Conquer URLs** are URLs that are linked to malware that connects the target computer to command and control servers. These are different from URLs that can be categorized as malicious as it is not always a virus that concerns to command and control URLs via external or remote servers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phishing URLs** are a form of attack that steals sensitive data, such as **personally identifiable information (PII)**, by either luring the user or disguising the URL as a legitimate or trustworthy URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "dataset = Path(Path.cwd()).resolve().parents[1] / \"introduction\" / \"datasets\" / \"dataset_phishing.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv(dataset)\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = raw_df[['url', 'status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.status == 'phishing'] = 1\n",
    "df.loc[df.status == 'legitimate'] = 0\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ipaddress(tokenized_words):\n",
    "    count = 0\n",
    "    for element in tokenized_words:\n",
    "        if str(element).isnumeric():  # fixed from encode() to str()\n",
    "            count += 1\n",
    "        else:\n",
    "            if count >= 4:\n",
    "                return 1\n",
    "            count = 0\n",
    "    return 1 if count >= 4 else 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def url_tokenize(url):\n",
    "    \"\"\"\n",
    "    Tokenizes a given URL using non-alphanumeric characters and returns:\n",
    "    1. The average token length (excluding empty tokens),\n",
    "    2. The number of valid (non-empty) tokens,\n",
    "    3. The length of the largest token.\n",
    "\n",
    "    Parameters:\n",
    "        url (str): The input URL string.\n",
    "\n",
    "    Returns:\n",
    "        list: [average_token_length (float), num_tokens (int), max_token_length (int)]\n",
    "    \"\"\"\n",
    "    tokenized_words = re.split(r'\\W+', url)\n",
    "    num_tokens = 0\n",
    "    total_length = 0\n",
    "    max_length = 0\n",
    "\n",
    "    for token in tokenized_words:\n",
    "        length = len(token)\n",
    "        if length > 0:\n",
    "            num_tokens += 1\n",
    "            total_length += length\n",
    "            if length > max_length:\n",
    "                max_length = length\n",
    "\n",
    "    try:\n",
    "        avg_length = total_length / num_tokens if num_tokens > 0 else 0\n",
    "        return [avg_length, num_tokens, max_length]\n",
    "    except Exception as e:\n",
    "        return [0, num_tokens, max_length]\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
